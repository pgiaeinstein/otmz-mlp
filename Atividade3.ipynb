{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySEHDT457sTW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DW-sOYBp7sTc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplo de implementação de Rede Neural\n",
    "\n",
    "Entende-se por *DeepLearning* uma técnica de aprendizado de máquina que ensina o computador a realizar o que humanos fazem por natureza: Aprender por exemplo.\n",
    "\n",
    "Redes Neurais são o estado da arte no que tange computação cognitiva nos dias atuais e suas aplicações dentro das ciências da computação vão desde carros autônomos aos identificadores de face.\n",
    "\n",
    "Nós vamos entender como melhor como uma rede neural funciona quando abordado em computação cognitiva, mas para um breve resumo; Temos um conjunto de vetores de entrada, estes vetores tem seu valor original modificado pelas n camadas escondidas do modelo até que seu valor seja transformado em um vetor de saída.\n",
    "\n",
    "![SVM01](https://cdn-images-1.medium.com/max/1600/1*DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)\n",
    "\n",
    "Cada nó desta rede executa a soma de cada peso recebido por seus nós anteriores e tem sua multiplicação propagada por uma função de ativação:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGoVKfYE4o0L",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SVM02](https://github.com/pgiaeinstein/otmz-mlp/raw/master/img/2.jpg)\n",
    "\n",
    "A estrutura tenta representar o que ocorre em um neurônio quando estimulado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ZQlqZZF4s1o",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SVM03](https://www.codeproject.com/KB/AI/1205732/neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ep5HX8XG4tQd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SVM04](https://cdn-images-1.medium.com/max/2000/1*1Jr-Lt9vcEOW2opvZyLbdA.png)\n",
    "\n",
    "Diferente dos modelos apresentados anteriormente, uma rede neural trabalha melhor com um número maior de features e pode precisar de um número muito maior de entradas de treino para convergir de maneira satisfatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KiwZRW717sTf"
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1538208719010,
     "user": {
      "displayName": "Fernando Secol",
      "photoUrl": "",
      "userId": "03337346942151607429"
     },
     "user_tz": 180
    },
    "id": "7d2Sjhfv7sTm",
    "outputId": "a62165bd-f58e-41e8-f4e3-b0367800279b",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('rEDzUT3ymw4', width=720, height=560)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando uma base de dados para classificação\n",
    "\n",
    "`make_classification` cria uma amostra randômica para estudos que envolvem classificação.\n",
    "\n",
    "---\n",
    "\n",
    "| Parâmetro | Descrição |\n",
    "|--|--|\n",
    "| n_samples | O número de amostras |\n",
    "| n_features | O número de features |\n",
    "| random_state | A semente utilizada para criar as amostras |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets.samples_generator import make_classification, make_regression\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize = (15, 10))\n",
    "    plt.plot(history.epoch, np.array(history.history['acc']), label='Train Acc')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_acc']), label = 'Val Acc')\n",
    "    plt.title('model accuracy')\n",
    "    plt.gca().set_ylim(top=1, bottom=0)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    plt.figure(figsize = (15, 10))\n",
    "    plt.title('model loss')\n",
    "    plt.gca().set_ylim(top=1, bottom=0)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['loss']), label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_loss']), label = 'Val loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8A4dOsL7sT-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Separando nossa informação em treino / teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C65AMpY_ZGg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Padronizando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A padronização realiza a seguinte operação:\n",
    "    \n",
    "$$ \n",
    "X_i = \\frac{X_i \\times \\overline{X}}{std_X}\n",
    "$$\n",
    "\n",
    "Basicamente o que estamos realizando é ignorar a distribuição original da nossa base. Transformaremos os dados para obter uma média muito próxima de 0 e desvio padrão próximo de 1, sendo assim não teremos valores com grande variância na nossa base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3x3rXjAf_dCT",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "scaler  = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALYMYdJS7sVd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensorflow\n",
    "\n",
    "O [TensorFlow™](https://www.tensorflow.org/?hl=pt-br) é uma biblioteca de software de código aberto para computação numérica que usa gráficos de fluxo de dados.\n",
    "\n",
    "[TensorFlow Playground](https://playground.tensorflow.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkdZzxb_EZ0H",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequential()\n",
    "\n",
    "`Sequential` é a classe que encapsula a lista de camadas que que dará forma ao modelo.\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape = (500,)))\n",
    "model.add(Dense(32))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WyQD0_fHc-s",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dense\n",
    "\n",
    "`Dense` é a classe que implementa uma camada do modelo.\n",
    "\n",
    "---\n",
    "\n",
    "| Parâmetro | Descrição |\n",
    "|--|--|\n",
    "| units | Dimensão da camada |\n",
    "| activation | A função de ativação dos nós |\n",
    "| input_shape | Dimensão dos inputs da rede |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZB98qeIJpG7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### tensorflow.keras.models.Sequential.compile\n",
    "\n",
    "Compila o modelo, geralmente recebe como parâmetro `loss`, `optimizer`, `metrics`.\n",
    "\n",
    "---\n",
    "\n",
    "| Parâmetro | Descrição |\n",
    "|--|--|\n",
    "| loss | Função considerada para cálculo do erro de saída do modelo |\n",
    "| optimizer | Função utilizada para otimizar o modelo |\n",
    "| metrics | Lista de métricas utilizadas para medir o desempenho do modelo durante o treino e teste |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(20, input_dim=20, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(40, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjJhHx177sVs",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Layer (type) - Retorna nome da camada e tipo\n",
    "- Output Shape - Retorna dimensão do vetor\n",
    "- Param # - Retorna a o resultado de $inputs \\times nós + bias $\n",
    "\n",
    "Ex. $20 \\times 20 + 20 = 420$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-ljyfhUlgY9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Como identificar Overfitting e Underfitting?\n",
    "\n",
    "Overfiting e Underfitting são o caso de resultados ruins em modelos de inteligência artificial.\n",
    "\n",
    "Podemos classificar como:\n",
    "\n",
    "- **Underfitting**\n",
    " - O modelo tem resultados ruins com a parcela de treino e validação, ou seja, o modelo não é capaz de entregar o resultado esperado por causa de sua arquitetura ou da qualidade da informação que lhe é apresentada.\n",
    " \n",
    "\n",
    "- **Overfitting**\n",
    " - O modelo tem resultados excelentes com sua parcela de treinamento, mas é incapaz de reproduzir os mesmos resultados com a parcela de validação.\n",
    " \n",
    " ![PIC2](https://shapeofdata.files.wordpress.com/2013/02/overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bl4A_4rcqjib",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Underfitting\n",
    "\n",
    "- Quando verificamos que o erro da parcela de treino é menor que a de validação e existe uma tendência de queda na parcela de validação, ou seja, esse valor de erro pode melhorar com um número maior de épocas.\n",
    "\n",
    " ![PIC3](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/Diagnostic-Line-Plot-Showing-an-Underfit-Model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgh9m6V8ruc-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Outro exemplo é quando temos um comportamento parecido entre a curva de treino e validação, porém, temos uma variação no erro entre estas curvas. Esse comportamento pode ser causado por um *underfit* da rede e, neste caso, pode ser corrigido modificando a estrutura da rede.\n",
    "\n",
    "\n",
    " ![PIC4](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/Diagnostic-Line-Plot-Showing-an-Underfit-Model-via-Status.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLU_1A6Sretc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Overfitting\n",
    "\n",
    "- Quando verificamos que o erro da parcela de treino melhora quanto maior é o número de épocas, porém, a parcela de validação tem um comportamento completamente oposto ou vemos este erro diminuir até um determinado ponto e depois degradar.\n",
    "\n",
    " ![PIC3](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/Diagnostic-Line-Plot-Showing-an-Overfit-Model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LehF-jmsvvAQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Podemos combater o *overfit* da rede adicionando uma regularização dos peso do modelo ou uma política de dropout.\n",
    "\n",
    "#### Regularização de peso\n",
    "\n",
    "- **L1 regularization**\n",
    " - O custo adicionado é proporcional a soma dos valores absolutos dos pesos.\n",
    "\n",
    "- **L2 regularization**\n",
    " - O custo adicionado é proporcional a soma dos valores quadráticos dos pesos.\n",
    " \n",
    "Em poucas palavras, L1 tem o mesmo efeito de reduzir o número de inputs da rede, fazendo com que inputs que tem peso pequeno se aproximem de zero e reduzindo o ruído causado. L2 resulta valores de peso geral menores e estabiliza os pesos quando há alta correlação entre os recursos de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRenDJF-0Wxr",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Dropout\n",
    "\n",
    "Dropout se resume em, aleatoriamente, desligar conexões entre os nós de duas camadas. Diminuindo assim a complexidade da arquitetura da rede.\n",
    "\n",
    " ![PIC3](https://cdn-images-1.medium.com/max/800/1*iWQzxhVlvadk6VAJjsgXgg.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1538208758849,
     "user": {
      "displayName": "Fernando Secol",
      "photoUrl": "",
      "userId": "03337346942151607429"
     },
     "user_tz": 180
    },
    "id": "Lvx9U6lN1T4c",
    "outputId": "e77784f8-76e0-44b7-e4e8-e8c45c935109",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('DEMmkFC6IGM', width = 720, height = 560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1538208757728,
     "user": {
      "displayName": "Fernando Secol",
      "photoUrl": "",
      "userId": "03337346942151607429"
     },
     "user_tz": 180
    },
    "id": "Xj6v8q45sssQ",
    "outputId": "e5b03ea5-a724-4f87-fee0-42ad029250df",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('0h8lAm5Ki5g', width = 720, height = 560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=250, validation_split=0.2, verbose=True)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, acc] = model.evaluate(X_test, y_test)\n",
    "print(\"Acc: {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output = model.predict(X_test)\n",
    "print(pred_output[:10])\n",
    "pred_output = (pred_output > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test).flatten()\n",
    "test_preds_bin = (test_preds > 0.5)\n",
    "test_preds_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm  = confusion_matrix(y_test, test_preds_bin)\n",
    "sns.heatmap(cm, annot = True, fmt='g', cmap = 'winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0wTyaGJPwWw"
   },
   "source": [
    "## Curva ROC\n",
    "\n",
    "A Curva de operação do receptor (*Receiver Operationg Characteristic*)  é uma representação gráfica que ilustra o desempenho (ou performance) de um sistema classificador binário e como o seu limiar de discriminação é variado. [Wikipedia](https://pt.wikipedia.org/wiki/Caracter%C3%ADstica_de_Opera%C3%A7%C3%A3o_do_Receptor)\n",
    "\n",
    " ![PIC6](https://ncss-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/ROC-Curves-Empirical-19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58gomEGBTiu0"
   },
   "source": [
    "#### Sensitivity\n",
    "\n",
    "Também chamada de *true positive rate*, *recall* ou *probabilidade de detecção*. Mede a proporção de positivos realmente detectados como positivos.\n",
    "\n",
    "$$\n",
    "TPR = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "#### Specificity\n",
    "\n",
    "Também chamada de *true negative rate*, mede a proporção de negativos realmente detectados como negativos.\n",
    "\n",
    "$$\n",
    "TNR = \\frac{TN}{TN + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1538208796630,
     "user": {
      "displayName": "Fernando Secol",
      "photoUrl": "",
      "userId": "03337346942151607429"
     },
     "user_tz": 180
    },
    "id": "uRoJXeErPvLh",
    "outputId": "858ec9cd-5966-4c6a-c682-e38c57f25ff0"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('21Igj5Pr6u4', width = 720, height = 560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, test_preds)\n",
    "auc_calc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.plot(fpr, tpr, label='Modelo (area = {:.3f})'.format(auc_calc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='best')\n",
    "plt.plot([0, 1], [0, 1], 'k--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "\n",
    "Dado o problema apresentado na aula passada, tente modelar uma rede para realizar a mesma classificação para o caso de diabetes.\n",
    "\n",
    "Compare os valores obtidos.\n",
    "\n",
    "Ao separar as bases em teste e treino, garanta que exatamente 20% seja reservado para a parcela de teste e utilize um random_state igual a 42 como demonstrado abaixo:\n",
    "\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diabetes = pd.read_csv('https://raw.githubusercontent.com/pgiaeinstein/otmz-mlp/master/diabetes.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diabetes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolução\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
